{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11b2a2-cd52-4cfa-be0f-2fa5b6d7a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "\n",
      "Beginning search...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#       sleeping cat\n",
    "#         |\\      _,,,---,,_\n",
    "#   ZZZzz /,`.-'`'    -.  ;-;;,_\n",
    "#        |,4-  ) )-,_. ,\\ (  `'-'\n",
    "#       '---''(_/--'  `-'\\_)  \n",
    "#Used and modified Professor Eamonn Keogh's sample code\n",
    "\n",
    "smalldata = np.loadtxt(\"./CS170_Small_Data__93.txt\")\n",
    "largedata = np.loadtxt(\"./CS170_Large_Data__15.txt\")\n",
    "\n",
    "#nn distance function using euclidean distance\n",
    "def dist(obj, data, fts):\n",
    "    distance = 0\n",
    "    for i in fts:\n",
    "        distance += (obj[i-1] - data[i-1])**2\n",
    "    return np.sqrt(distance)\n",
    "        \n",
    "#feature search function\n",
    "def feature_search_demo(data, df):\n",
    "            \n",
    "    #initializes the list of current features and best set of features\n",
    "    current = []\n",
    "    best_set = []\n",
    "    best_best_acc = 0\n",
    "    \n",
    "    print(\"\\nBeginning search...\\n\")\n",
    "    \n",
    "    #loops over features to consider\n",
    "    for i in range(0, data.shape[1]):\n",
    "        #print(f\"On level {i} of the search tree\")\n",
    "        addedft = []\n",
    "        bestacc = 0\n",
    "        \n",
    "        if(i == 0):\n",
    "            best_best_acc = cross_validation(data, current, 0)\n",
    "            df2 = {'Current Feature Set': str(current), 'Accuracy': str(round(best_best_acc*100, 3))}\n",
    "            df = df.append(df2, ignore_index = True) \n",
    "        else:\n",
    "            #loops over possible features to add\n",
    "            for j in range(1, data.shape[1]):\n",
    "                if(j not in current):\n",
    "                   #print(f\"  Consider adding feature {j}\")\n",
    "\n",
    "                    #computing accuracy of the feature set with the added feature and compare to the current best accuracy\n",
    "                   acc = cross_validation(data, current, j)\n",
    "                   if acc > bestacc:\n",
    "                       bestacc = acc\n",
    "                       addedft = j\n",
    "        \n",
    "            current.append(addedft)\n",
    "            df2 = {'Current Feature Set': str(current), 'Accuracy': str(round(bestacc*100, 3))}\n",
    "            df = df.append(df2, ignore_index = True)          \n",
    "            #print(f\"\\nOn level {i} I added the feature {addedft} to the feature set which is now {current}\")    \n",
    "            #print(f\"The feature had an accuracy of {round(bestacc*100, 3)}%\\n\")\n",
    "        \n",
    "            #finds the best accuracy out of all feature sets computed\n",
    "            if bestacc > best_best_acc:\n",
    "                best_best_acc = bestacc\n",
    "                best_set.append(addedft)\n",
    "        \n",
    "    print(f\"done\")\n",
    "    return df\n",
    "   \n",
    "#backwards feature search function, very similar to the forward search function             \n",
    "def backwards_search_demo(data, df):\n",
    "    \n",
    "    current = []\n",
    "    best_set = []\n",
    "    best_best_acc = 0\n",
    "    \n",
    "    #adds all features to the current set\n",
    "    for i in range(1, data.shape[1]):\n",
    "        current.append(i)\n",
    "        best_set.append(i)\n",
    "        \n",
    "    print(\"\\nBeginning search...\\n\")\n",
    "    for i in range(0, data.shape[1]):\n",
    "        #print(f\"On level {i} of the search tree\")\n",
    "        addedft = 0\n",
    "        bestacc = 0\n",
    "        if(i == 0):\n",
    "            best_best_acc = bw_cross_validation(data, current, 0)\n",
    "            df2 = {'Current Feature Set': str(current), 'Accuracy': str(round(best_best_acc*100, 3))}\n",
    "            df = df.append(df2, ignore_index = True) \n",
    "            #print('\\n')\n",
    "        else:\n",
    "            for j in range(1, data.shape[1]):\n",
    "                if(j in current):\n",
    "                    #print(f\"  Consider removing feature {j}\")\n",
    "\n",
    "                    acc = bw_cross_validation(data, current, j)\n",
    "                    if acc > bestacc:\n",
    "                       bestacc = acc\n",
    "                       addedft = j\n",
    "        \n",
    "            #removes ft from current set\n",
    "            current.remove(addedft)     \n",
    "            df2 = {'Current Feature Set': str(current), 'Accuracy': str(round(bestacc*100, 3))}\n",
    "            df = df.append(df2, ignore_index = True)          \n",
    "            #print(f\"\\nOn level {i} I removed the feature {addedft} to the feature set which is now {current}\")    \n",
    "            #print(f\"The feature had an accuracy of {round(bestacc*100, 3)}%\\n\")\n",
    "            if bestacc > best_best_acc:\n",
    "                best_best_acc = bestacc\n",
    "                best_set.remove(addedft)\n",
    "        \n",
    "    print(f\"done\")\n",
    "    return df\n",
    "                       \n",
    "\n",
    "#computes accuracy of the classifier\n",
    "def cross_validation(data, current, addedft):\n",
    "    classified = 0\n",
    "    #copies current feature set and the added feature into the curr array\n",
    "    curr = 0\n",
    "    curr = current[:]\n",
    "    if(addedft != 0):\n",
    "        curr.append(addedft)\n",
    "    \n",
    "    #loop over all instances in the dataset\n",
    "    for i in range(0, data.shape[0]):\n",
    "        \n",
    "        #object to classify, is row i with all features from row one on\n",
    "        obj_to_classify = data[i, 1:]\n",
    "        \n",
    "        #label i\n",
    "        label_obj_to_classify = data[i, 0]\n",
    "        \n",
    "        nn_dist = 999999\n",
    "        nn_loc = 999999\n",
    "        \n",
    "        #loops through all instances and calculates nn distances\n",
    "        for j in range(data.shape[0]):\n",
    "            \n",
    "            if j != i:\n",
    "                distance = dist(obj_to_classify, data[j][1:], curr)\n",
    "                if distance < nn_dist:\n",
    "                    \n",
    "                    nn_dist = distance\n",
    "                    nn_loc = j\n",
    "                    nn_label = data[nn_loc, 0]\n",
    "        \n",
    "        #calculates total classified labels            \n",
    "        if label_obj_to_classify == nn_label:\n",
    "            classified+=1\n",
    "    #print(f\"Time: {round(time2 - time1, 4)}\\n\")\n",
    "    #print(f\"  Accuracy of set {curr}: {round(classified / data.shape[0], 2)}\")        \n",
    "    return classified / len(data)\n",
    "\n",
    "#essentially the same as forward except it will remove instead of appending features                \n",
    "def bw_cross_validation(data, current, addedft):\n",
    "    classified = 0\n",
    "    curr = 0\n",
    "    curr = current[:]\n",
    "    if(addedft != 0):\n",
    "        curr.remove(addedft)\n",
    "    for i in range(0, data.shape[0]):\n",
    "        obj_to_classify = data[i, 1:]\n",
    "        label_obj_to_classify = data[i, 0]\n",
    "        \n",
    "        nn_dist = 999999\n",
    "        nn_loc = 999999\n",
    "        for j in range(data.shape[0]):\n",
    "            \n",
    "            if j != i:\n",
    "                distance = dist(obj_to_classify, data[j][1:], curr)\n",
    "                if distance < nn_dist:\n",
    "                    \n",
    "                    nn_dist = distance\n",
    "                    nn_loc = j\n",
    "                    nn_label = data[nn_loc, 0]\n",
    "                    \n",
    "        if label_obj_to_classify == nn_label:\n",
    "            classified+=1\n",
    "    #print(f\"  Accuracy of set {curr}: {round(classified / data.shape[0], 2)}\")        \n",
    "    return classified / len(data)\n",
    "                \n",
    "        \n",
    "        \n",
    "def main():\n",
    "    df = pd.DataFrame(columns=['Current Feature Set', 'Accuracy'])\n",
    "    df3 = pd.DataFrame(columns=['Current Feature Set', 'Accuracy'])\n",
    "    data = largedata\n",
    "    print('a')\n",
    "    time1 = time.time()\n",
    "    df = feature_search_demo(data, df)\n",
    "    time2 = time.time()\n",
    "    print(f\"Time: {round(time2 - time1, 4)}\\n\")\n",
    "    time1 = 0\n",
    "    time2 = 0\n",
    "    time1 = time.time()\n",
    "    df3 = backwards_search_demo(data, df3)\n",
    "    time2 = time.time()\n",
    "    print(f\"Time: {round(time2 - time1, 4)}\\n\")\n",
    "    print(df)\n",
    "    print(df3)\n",
    "    df3.to_csv(\"largebw.csv\")\n",
    "    df.to_csv(\"large.csv\")\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f3a9b-cb49-443c-8fb8-3b9a1c405f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1db7dc-6bba-475e-90d9-c6a5198d1303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb6f96-77c1-4622-bd1b-99129e554ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
